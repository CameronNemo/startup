High Priority:

 * Respawn timeouts are actually broken with the new model, since they apply
   to the single instance that is destroyed.

 * Expand variables; now we have the concept of a job environment, we can
   expand strings in the configuration with them; I'm particularly thinking
   of the stop event tree here.

 * Named instances; expand an instance variable string using variables from
   the environment to get a unique string we can lookup in the job.  If this
   exists already, we're not a new instance.

 * When we start or stop a job by a command, a reference to the command should
   be stored in the Job instead of blocking with the same rules.  It may be
   useful to not just have failed=TRUE/FALSE for job_unblock() but a more
   detailed reason about why the job is being unblocked, so the command could
   exit saying "ok", "failed", "stopped by event", etc.

 * Restore IPC using D-BUS.

 * Configuration reloading needs to happen with an initctl command;
   we also need to support re-exec via initctl as well.  Should we get
   rid of the signals, or at least change the TERM one?

 * Restore serialisation of state between upstart processes.  Having made
   the structures in memory more sane, this should be easier again, as
   long as we send things in this order:

    * Event queue
    * Job hash (referencing cause and blocked events by id, also need to
      ensure we handle instance jobs proeprly)
   
   I want to use the IPC protocol for this, since it's somewhat stable
   now.  Handing off will still use the "fork a child, exec in the parent"
   model, except for the following.

    * Leave the control socket open, clear the cloexec flag, and pass its
      file descriptor number to the new init process.
    * In the child, close the control socket we had open and open an
      ordinary socket; blocking-write the information to that and then die.


Medium Priority:

 * Need to add dependencies to jobs, which are files that must exist before
   the job can be started (because Debian/Ubuntu like to litter config files
   like jobs)

 * Resources, "uses cpu 1.0" -- where cpu has a defined max (default 1.0);
   which state do we keep it in while it's waiting?

 * job_handle_event has become someone large, with two blocks of code that
   look very similar.  In addition, these blocks of code will be very similar
   to those for manually starting a job; find some way to reduce these to
   a common function?

 * Handling of utmp and wtmp needs to be somewhat better.
   - common function to read/write to utmp and wtmp
   - should be able to read current runlevel (as runlevel does right now)
   - should be able to set current runlevel (as runlevel does right now)
   - move runlevel setting code into telinit before it emits the event,
     which should include RUNLEVEL and PREVLEVEL in the environment
   - shutdown should write a shutdown entry
   - reboot should check the current runlevel, and exec shutdown based on 
     that, as well as -f
   - reboot should write the wtmp shutdown record
   - somehow on startup we should write the reboot record as early as we
     can
   - init needs to grow "utmp XXX", which maintains INIT_PROCESS and
     DEAD_PROCESS entries for the given ut_id (3 chars max), used for getty


Low Priority:

 * Iterating through every Job's start and stop events is messy; we should
   have some kind of match lookup table to make it easier.

 * Likewise iterating through all the Jobs to find a pid is messy; we
   should have a lookup table for these too.

 * process_setup_console is due for an overhaul as well; especially if
   we want to be able to pass file descriptors in.  Am somewhat tempted
   to add a magic CONSOLE_DEFAULT option which tries fd, logging, null,
   etc.  and use CONSOLE_LOGGED to mean "die if logd isn't around".

 * We always want /dev/fd/NNN to be /dev/fd/3, we should have some way
   to instruct process_spawn to do that.

 * We may need to KILL scripts, e.g. post-start; especially when the goal
   changes.  Or perhaps just after a timeout?

 * May need a way to force ignoring of the KILL signal, and assuming that
   a job that won't die really has.

 * Make the logd raise/wait/kill interlock compatible with the "wait for stop"
   behaviour.

 * Replace logd with something else that's more standard in the system,
   and just use a normal API to communicate with it.

 * logd is currently disabled because of the problem where it goes away,
   and the scripts being run end up vanishing because they can't write
   data.

 * Get the LANG environment variable somehow.


Future Features:

 * Roles; services define roles that they can perform ("web server") and
   can be found by their role.  Other jobs could require that a role be
   performed for them to start (creeping into deps here).  Use affinity
   tags to work out which of many services to start.

 * Per-user services; will need to use PAM to set up the session.
   We want to do this for "root-user services" but not for jobs/tasks

 * Passing of file descriptors from event over control socket.

 * Register jobs over the control socket, ideal way is to register some kind
   of automatic source and attach them to that.

 * Temporal events ("15m after startup")

 * Scheduled times ("every day at 3:00")

 * Load average checking, maybe have separate CPU, Network and I/O
   stats?  See also resources.

 * Actions: "reload" and optional replacements for "stop", "start", etc.

   This is mostly just a matter of deciding policy for when they can be run,
   and adding "user processes" onto the end of the job->process array.

 * Alternative script interpreters; "start script python".

   Would be done by making script a char *, and putting the interpreter into
   command?

 * Watershed jobs (this actually might apply to events, since you might
   want to try starting again if a particular event has come in since you
   were last started)
