Before 0.5.0:

 * Asynchronous Emit method which is blocked by the event, and the reply
   generated when the event is finished.

 * event_pending_handle_jobs is very large, complicated and most of it is
   entirely in the wrong place.  The two blocks of code to deal with stop
   and start events are very similar, and will be basically identical for
   the start and stop command cases.  Reduce to common functions that this
   can call.

 * It may be useful to not just have failed=TRUE/FALSE for job_unblock() but a
   more detailed reason about why the job is being unblocked, so the command
   could exit saying "ok", "failed", "stopped by event", etc.

 * I'm still not convinced that just clearing blocking is the right approach,
   and still think we need some kind of next_blocking list of things that
   will still be blocked next time around.  Restores some of the older
   behaviour in that "start" will block until stopped, and fail with the
   fact it was stopped.


0.5.x series:

 * Handling of utmp and wtmp needs to be somewhat better.
   - common function to read/write to utmp and wtmp
   - should be able to read current runlevel (as runlevel does right now)
   - should be able to set current runlevel (as runlevel does right now)
   - move runlevel setting code into telinit before it emits the event,
     which should include RUNLEVEL and PREVLEVEL in the environment
   - shutdown should write a shutdown entry
   - reboot should check the current runlevel, and exec shutdown based on 
     that, as well as -f
   - reboot should write the wtmp shutdown record
   - somehow on startup we should write the reboot record as early as we
     can
   - init needs to grow "utmp XXX", which maintains INIT_PROCESS and
     DEAD_PROCESS entries for the given ut_id (3 chars max), used for getty

 * Need to add dependencies to jobs, which are files that must exist before
   the job can be started (because Debian/Ubuntu like to litter config files
   like jobs)

 * Resources, "uses cpu 1.0" -- where cpu has a defined max (default 1.0);
   which state do we keep it in while it's waiting?


Later:

 * Restore serialisation of state between upstart processes, I guess we'll
   use a D-Bus API to do this.  Most sense would be a peer-to-peer D-Bus
   connection so don't need the bus (think initramfs), but we also need
   to pass over the bus connection so we don't drop that.

    - Pass the Event queue first since Jobs refer to it
    - Register each ConfSource, ConfFile, JobClass and Job, setting
      the status of each
    - Join up the Event queue and Job structures

    - What about commends blocked on event emissions or jobs?


Anytime:

 * Iterating through every Job's start and stop events is messy; we should
   have some kind of match lookup table to make it easier.

 * Likewise iterating through all the Jobs to find a pid is messy; we
   should have a lookup table for these too.  Ideally we'd have a JobProcess
   structure combining type, pid and a link to the job -- then all the
   job_process_* functions would just accept those

 * system_setup_console is due for an overhaul as well; especially if
   we want to be able to pass file descriptors in.  Am somewhat tempted
   to add a magic CONSOLE_DEFAULT option which tries fd, logging, null,
   etc.  and use CONSOLE_LOGGED to mean "die if logd isn't around".

 * We always want /dev/fd/NNN to be /dev/fd/3, we should have some way
   to instruct process_spawn to do that.

 * We may need to KILL scripts, e.g. post-start; especially when the goal
   changes.  Or perhaps just after a timeout?

 * May need a way to force ignoring of the KILL signal, and assuming that
   a job that won't die really has.

 * Make the logd raise/wait/kill interlock compatible with the "wait for stop"
   behaviour.

 * Replace logd with something else that's more standard in the system,
   and just use a normal API to communicate with it.

 * logd is currently disabled because of the problem where it goes away,
   and the scripts being run end up vanishing because they can't write
   data.

 * Get the LANG environment variable somehow.


Future Features:

 * Roles; services define roles that they can perform ("web server") and
   can be found by their role.  Other jobs could require that a role be
   performed for them to start (creeping into deps here).  Use affinity
   tags to work out which of many services to start.

 * Per-user services; will need to use PAM to set up the session.
   We want to do this for "root-user services" but not for jobs/tasks

 * Passing of file descriptors from event over control socket.

 * Register jobs over the control socket, ideal way is to register some kind
   of automatic source and attach them to that.

 * Temporal events ("15m after startup")

 * Scheduled times ("every day at 3:00")

 * Load average checking, maybe have separate CPU, Network and I/O
   stats?  See also resources.

 * Actions: "reload" and optional replacements for "stop", "start", etc.

   This is mostly just a matter of deciding policy for when they can be run,
   and adding "user processes" onto the end of the job->process array.

 * Alternative script interpreters; "start script python".

   Would be done by making script a char *, and putting the interpreter into
   command?

 * Watershed jobs (this actually might apply to events, since you might
   want to try starting again if a particular event has come in since you
   were last started)
